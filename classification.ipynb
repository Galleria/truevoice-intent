{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `true-intent` Destination Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We provide 3 benchmarks for the 7-class multi-class classification of `destination` column in `truevoice-intnet` dataset: [fastText](https://github.com/facebookresearch/fastText), LinearSVC and [ULMFit](https://github.com/cstorm125/thai2fit). In the transfer learning cases, we first finetune the embeddings using all data. The test set contains 20% of all data split by [TrueVoice](http://www.truevoice.co.th/). The rest is split into 85/15 train-validation split randomly. Performance metrics are micro-averaged accuracy and F1 score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| model     | accuracy | micro-F1 |\n",
    "|-----------|----------|----------|\n",
    "| fastText  | 0.384116 | 0.384116 |\n",
    "| LinearSVC | 0.807876 | 0.327565 |\n",
    "| ULMFit    |       0  |      0   |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pythainlp import word_tokenize\n",
    "from tqdm import tqdm_notebook\n",
    "from collections import Counter\n",
    "import re\n",
    "\n",
    "#viz\n",
    "from plotnine import *\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "def replace_newline(t):\n",
    "    return re.sub('[\\n]{1,}', ' ', t)\n",
    "\n",
    "ft_data = 'ft_data/'\n",
    "\n",
    "y = 'destination'\n",
    "nb_class = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import emoji\n",
    "def replace_url(text):\n",
    "    URL_PATTERN = r\"\"\"(?i)\\b((?:https?:(?:/{1,3}|[a-z0-9%])|[a-z0-9.\\-]+[.](?:com|net|org|edu|gov|mil|aero|asia|biz|cat|coop|info|int|jobs|mobi|museum|name|post|pro|tel|travel|xxx|ac|ad|ae|af|ag|ai|al|am|an|ao|aq|ar|as|at|au|aw|ax|az|ba|bb|bd|be|bf|bg|bh|bi|bj|bm|bn|bo|br|bs|bt|bv|bw|by|bz|ca|cc|cd|cf|cg|ch|ci|ck|cl|cm|cn|co|cr|cs|cu|cv|cx|cy|cz|dd|de|dj|dk|dm|do|dz|ec|ee|eg|eh|er|es|et|eu|fi|fj|fk|fm|fo|fr|ga|gb|gd|ge|gf|gg|gh|gi|gl|gm|gn|gp|gq|gr|gs|gt|gu|gw|gy|hk|hm|hn|hr|ht|hu|id|ie|il|im|in|io|iq|ir|is|it|je|jm|jo|jp|ke|kg|kh|ki|km|kn|kp|kr|kw|ky|kz|la|lb|lc|li|lk|lr|ls|lt|lu|lv|ly|ma|mc|md|me|mg|mh|mk|ml|mm|mn|mo|mp|mq|mr|ms|mt|mu|mv|mw|mx|my|mz|na|nc|ne|nf|ng|ni|nl|no|np|nr|nu|nz|om|pa|pe|pf|pg|ph|pk|pl|pm|pn|pr|ps|pt|pw|py|qa|re|ro|rs|ru|rw|sa|sb|sc|sd|se|sg|sh|si|sj|Ja|sk|sl|sm|sn|so|sr|ss|st|su|sv|sx|sy|sz|tc|td|tf|tg|th|tj|tk|tl|tm|tn|to|tp|tr|tt|tv|tw|tz|ua|ug|uk|us|uy|uz|va|vc|ve|vg|vi|vn|vu|wf|ws|ye|yt|yu|za|zm|zw)/)(?:[^\\s()<>{}\\[\\]]+|\\([^\\s()]*?\\([^\\s()]+\\)[^\\s()]*?\\)|\\([^\\s]+?\\))+(?:\\([^\\s()]*?\\([^\\s()]+\\)[^\\s()]*?\\)|\\([^\\s]+?\\)|[^\\s`!()\\[\\]{};:'\".,<>?«»“”‘’])|(?:(?<!@)[a-z0-9]+(?:[.\\-][a-z0-9]+)*[.](?:com|net|org|edu|gov|mil|aero|asia|biz|cat|coop|info|int|jobs|mobi|museum|name|post|pro|tel|travel|xxx|ac|ad|ae|af|ag|ai|al|am|an|ao|aq|ar|as|at|au|aw|ax|az|ba|bb|bd|be|bf|bg|bh|bi|bj|bm|bn|bo|br|bs|bt|bv|bw|by|bz|ca|cc|cd|cf|cg|ch|ci|ck|cl|cm|cn|co|cr|cs|cu|cv|cx|cy|cz|dd|de|dj|dk|dm|do|dz|ec|ee|eg|eh|er|es|et|eu|fi|fj|fk|fm|fo|fr|ga|gb|gd|ge|gf|gg|gh|gi|gl|gm|gn|gp|gq|gr|gs|gt|gu|gw|gy|hk|hm|hn|hr|ht|hu|id|ie|il|im|in|io|iq|ir|is|it|je|jm|jo|jp|ke|kg|kh|ki|km|kn|kp|kr|kw|ky|kz|la|lb|lc|li|lk|lr|ls|lt|lu|lv|ly|ma|mc|md|me|mg|mh|mk|ml|mm|mn|mo|mp|mq|mr|ms|mt|mu|mv|mw|mx|my|mz|na|nc|ne|nf|ng|ni|nl|no|np|nr|nu|nz|om|pa|pe|pf|pg|ph|pk|pl|pm|pn|pr|ps|pt|pw|py|qa|re|ro|rs|ru|rw|sa|sb|sc|sd|se|sg|sh|si|sj|Ja|sk|sl|sm|sn|so|sr|ss|st|su|sv|sx|sy|sz|tc|td|tf|tg|th|tj|tk|tl|tm|tn|to|tp|tr|tt|tv|tw|tz|ua|ug|uk|us|uy|uz|va|vc|ve|vg|vi|vn|vu|wf|ws|ye|yt|yu|za|zm|zw)\\b/?(?!@)))\"\"\"\n",
    "    return re.sub(URL_PATTERN, 'xxurl', text)\n",
    "\n",
    "def replace_rep(text):\n",
    "    def _replace_rep(m):\n",
    "        c,cc = m.groups()\n",
    "        return f'{c}xxrep'\n",
    "    re_rep = re.compile(r'(\\S)(\\1{2,})')\n",
    "    return re_rep.sub(_replace_rep, text)\n",
    "\n",
    "def ungroup_emoji(toks):\n",
    "    res = []\n",
    "    for tok in toks:\n",
    "        if emoji.emoji_count(tok) == len(tok):\n",
    "            for char in tok:\n",
    "                res.append(char)\n",
    "        else:\n",
    "            res.append(tok)\n",
    "    return res\n",
    "\n",
    "def process_text(text):\n",
    "    #pre rules\n",
    "    res = text.lower().strip()\n",
    "    res = replace_url(res)\n",
    "    res = replace_rep(res)\n",
    "    \n",
    "    #tokenize\n",
    "    res = [word for word in res.split('|') if word and not re.search(pattern=r\"\\s+\", string=word)]\n",
    "    \n",
    "    #post rules\n",
    "    res = ungroup_emoji(res)\n",
    "    \n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train-validation-test Split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We perform 85/15 train-validation split in addition to the test split by [TrueVoice](http://www.truevoice.co.th/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10998, 5) (1941, 5) (3236, 5)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "all_df = pd.read_csv(f'mari_train.csv')\n",
    "all_df['destination'] = all_df.destination.map(lambda x: x.replace(' ','_'))\n",
    "train_df, valid_df = train_test_split(all_df, test_size=0.15, random_state=1412)\n",
    "train_df = train_df.reset_index(drop=True)\n",
    "valid_df = valid_df.reset_index(drop=True)\n",
    "test_df = pd.read_csv(f'mari_test.csv')\n",
    "test_df['destination'] = test_df.destination.map(lambda x: x.replace(' ','_'))\n",
    "print(train_df.shape, valid_df.shape, test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "billing_and_payment      0.301916\n",
       "internet                 0.190049\n",
       "promotions               0.182324\n",
       "other_queries            0.169654\n",
       "international_dialing    0.062732\n",
       "lost_and_stolen          0.060569\n",
       "true_money               0.032756\n",
       "Name: destination, dtype: float64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test set prevalence\n",
    "test_df['destination'].value_counts() / test_df.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [fastText](https://github.com/facebookresearch/fastText) Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We used embeddings pretrained on [Thai Wikipedia Dump](https://github.com/facebookresearch/fastText/blob/master/docs/pretrained-vectors.md) and finetuned them using all of `truevoice-intent` using skipgram model. After that, we do a multi-class classification and compute performance metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_txts = ['train','valid','test']\n",
    "dfs = [train_df,valid_df,test_df]\n",
    "\n",
    "for i in range(3):\n",
    "    df = dfs[i]\n",
    "    ft_lines = []\n",
    "    for _,row in df.iterrows():\n",
    "        ft_lab = f'__label__{row[y]}'\n",
    "        ft_text = replace_newline(f'{row[\"texts\"]}')\n",
    "        ft_line = f'{ft_lab} {ft_text}'\n",
    "        ft_lines.append(ft_line)\n",
    "\n",
    "    doc = '\\n'.join(ft_lines)\n",
    "    with open(f'{ft_data}{df_txts[i]}.txt','w') as f:\n",
    "        f.write(doc)\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for fasttext embedding finetuning\n",
    "ft_lines = []\n",
    "for _,row in all_df.iterrows():\n",
    "    ft_lab = '__label__0'\n",
    "    ft_text = replace_newline(f'{row[\"texts\"]}')\n",
    "    ft_line = f'{ft_lab} {ft_text}'\n",
    "    ft_lines.append(ft_line)\n",
    "\n",
    "doc = '\\n'.join(ft_lines)\n",
    "with open(f'{ft_data}df_all.txt','w') as f:\n",
    "    f.write(doc)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read 0M words\n",
      "Number of words:  538\n",
      "Number of labels: 1\n",
      "Progress: 100.0%  words/sec/thread: 31923  lr: 0.000000  loss: 2.440569  eta: 0h0m \n"
     ]
    }
   ],
   "source": [
    "#finetune with all data\n",
    "!/home/charin/fastText-0.1.0/fasttext skipgram \\\n",
    "-pretrainedVectors 'model/wiki.th.vec' -dim 300 \\\n",
    "-input ft_data/df_all.txt -output 'model/finetuned'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read 0M words\n",
      "Number of words:  19060\n",
      "Number of labels: 7\n",
      "Progress: 100.0%  words/sec/thread: 296072  lr: 0.000000  loss: 0.471060  eta: 0h0m \n"
     ]
    }
   ],
   "source": [
    "#train classifier\n",
    "!/home/charin/fastText-0.1.0/fasttext supervised \\\n",
    "-input 'ft_data/train.txt' -output 'model/classifier' \\\n",
    "-pretrainedVectors 'model/finetuned.vec' -epoch 5 -dim 300 -wordNgrams 2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get prediction\n",
    "preds = !/home/charin/fastText-0.1.0/fasttext predict 'model/classifier.bin' 'ft_data/test.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "enc = OneHotEncoder(handle_unknown='ignore')\n",
    "pred_lab = np.array([i[9:] for i in preds])\n",
    "\n",
    "enc_fit = enc.fit(test_df[y][:,None])\n",
    "pred_ohe = enc_fit.transform(pred_lab[:,None]).toarray()\n",
    "y_ohe = enc_fit.transform(test_df[y][:,None]).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4020395550061805 0.48687350835322196 0.9396110542476971 0.3285612025769506\n",
      "0.9409765142150803 0.11981566820276499 0.06403940886699508 0.9285714285714286\n",
      "0.8241656365883807 0.1929078014184397 0.11056910569105691 0.7555555555555555\n",
      "0.9508652657601978 0.31759656652360513 0.18877551020408162 1.0\n",
      "0.8340543881334982 0.12965964343598058 0.07285974499089254 0.5882352941176471\n",
      "0.8389987639060569 0.32947232947232946 0.21694915254237288 0.6844919786096256\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "#macro metrics\n",
    "for i in range(nb_class):\n",
    "    print(\n",
    "        (pred_ohe[:,i]==y_ohe[:,i]).mean(),\n",
    "        f1_score(pred_ohe[:,i],y_ohe[:,i]),\n",
    "        precision_score(pred_ohe[:,i],y_ohe[:,i]),\n",
    "        recall_score(pred_ohe[:,i],y_ohe[:,i])\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "micro metrics\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.3841161928306551,\n",
       " 0.3841161928306552,\n",
       " 0.3841161928306551,\n",
       " 0.3841161928306551)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('micro metrics')\n",
    "(pred_lab==test_df[y]).mean(), \\\n",
    "f1_score(test_df[y],pred_lab,average='micro'), \\\n",
    "precision_score(test_df[y],pred_lab,average='micro'), \\\n",
    "recall_score(test_df[y],pred_lab,average='micro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LinearSVC Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code for LinearSVC is provided by [@lukkiddd](https://github.com/lukkiddd)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = train_df['texts'], train_df[y]\n",
    "X_test, y_test = test_df['texts'], test_df[y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('tfidf', TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.float64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 2), norm='l2', preprocessor=None, smooth_idf=True,...ax_iter=1000,\n",
       "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "     verbose=0))])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "text_clf = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(tokenizer=process_text, ngram_range=(1,2))),\n",
    "    ('clf', LinearSVC()),\n",
    "])\n",
    "\n",
    "text_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "enc = OneHotEncoder(handle_unknown='ignore')\n",
    "pred_lab = text_clf.predict(X_test)\n",
    "\n",
    "enc_fit = enc.fit(test_df[y][:,None])\n",
    "pred_ohe = enc_fit.transform(pred_lab[:,None]).toarray()\n",
    "y_ohe = enc_fit.transform(test_df[y][:,None]).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.32756489493201485 0.4731234866828087 1.0 0.30986362194735173\n",
      "0.9372682323856613 0.0 0.0 0.0\n",
      "0.8105686032138443 0.006482982171799028 0.0032520325203252032 1.0\n",
      "0.9493201483312732 0.2807017543859649 0.16326530612244897 1.0\n",
      "0.830964153275649 0.007259528130671506 0.0036429872495446266 1.0\n",
      "0.8260197775030902 0.08752025931928686 0.04576271186440678 1.0\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "#macro metrics\n",
    "for i in range(nb_class):\n",
    "    print(\n",
    "        (pred_ohe[:,i]==y_ohe[:,i]).mean(),\n",
    "        f1_score(pred_ohe[:,i],y_ohe[:,i]),\n",
    "        precision_score(pred_ohe[:,i],y_ohe[:,i]),\n",
    "        recall_score(pred_ohe[:,i],y_ohe[:,i])\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "micro metrics\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.80787568426629,\n",
       " 0.32756489493201485,\n",
       " 0.32756489493201485,\n",
       " 0.32756489493201485)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('micro metrics')\n",
    "(pred_ohe==y_ohe).mean(), \\\n",
    "f1_score(y_ohe,pred_ohe,average='micro'), \\\n",
    "precision_score(y_ohe,pred_ohe,average='micro'), \\\n",
    "recall_score(y_ohe,pred_ohe,average='micro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [ULMFit](https://github.com/cstorm125/thai2fit) Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
